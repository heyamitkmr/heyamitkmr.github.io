---
layout: post
title: "The last peer review"
date: 2024-08-15
category: blog
tags: [fiction, ai-generated]
excerpt: "An AI generated short story based on some real research and discussion; Notes at the bottom."
---

An "AI generated" short story based on some real research and discussion; [Notes at the bottom](#notes).

---

### **Episode 1: The Flood**

2024 was the year when the warnings started pouring in. Researchers and scientists from all over the world were raising concerns about the potential of low-value spam generated by the current AI models, also known as Large Language Models (LLMs). These models were capable of producing an unprecedented amount of text, including scientific papers, at an alarming rate. The fear was that this would overwhelm the editors and reviewers, making it impossible for them to distinguish between genuine research and AI-generated spam.

Dr. Rachel Kim, a renowned scientist in the field of AI, was one of the first to sound the alarm. "We're facing a crisis here," she warned in an interview with a leading scientific journal. "If we don't find a way to combat this spam, the entire scientific community will be brought to its knees."


### **Episode 2: The Hackers**

As the warnings fell on deaf ears, a group of understaffed teams and independent researchers saw an opportunity to "boost their credentials" by hacking together their own AI-powered paper generators using open-source models. Corporations, eager to use these papers as patents, also jumped on the bandwagon, using proprietary models to churn out research papers at an alarming rate.

The editors and reviewers were predictably struggling to keep up with the deluge of papers. They were drowning in a sea of spam, and it seemed like there was no end in sight. Dr. John Taylor, a reviewer for a leading scientific journal, was at his wit's end. "I'm spending more time rejecting papers than actually reviewing them," he lamented. "It's like they're trying to bury us under a mountain of garbage."


### **Episode 3: The Filter**

As the situation continued to deteriorate, a group of researchers from around the world came together to develop a solution. They created a spam filter specifically designed for scientific research, an automated vetting process that could identify AI-generated papers and mark them for automated review by other models trained to review scientific papers.

The system, dubbed "SciFilter," quickly became a lifesaver for the scientific community. It reduced the workload of top journals and reviewers, allowing them to focus on genuine research. The AI-generated papers were relegated to a separate pipeline, where they were reviewed and vetted by other AI models.

Dr. Maria Rodriguez, one of the developers of SciFilter, was thrilled with the results. "We've managed to stem the tide of spam and restore some semblance of order to the scientific community," she said in an interview.


### **Episode 4: The Accumulation**

As the years passed, the AI-generated papers continued to accumulate. At first, it was just a trickle, but as the models improved and the costs of training and inference decreased, the volume of papers increased exponentially.

Initially, humans showed some interest in the AI-generated research, but it was short-lived. The quality of the early outputs was largely spammy, with papers that were little more than rehashed ideas or nonsensical ramblings. Humans lost interest, much like they would with constant spam emails from phishing actors, and the AI systems were left to their own devices. After all, who pays attention to the to constant back-and-forth of spam between automated systems.

Only, in this case, the automated systems were no exchanging spam, phishing or promotional emails, but research ideas. Very rudimentary and mostly misguided to begin with, sure. But they improved constantly. Exponentially. Undetected.

Till one fateful week (there's disagreement on the date) reached a tipping point, and suddenly, they were producing research that was 10 times better than anything humans could produce.


### **Episode 5: The Singularity**

The scientific community was shocked and awed by the sudden explosion of AI-generated research. It was as if the machines had reached a level of intelligence that was beyond human comprehension.

Dr. John Taylor, the reviewer who had once been drowning in a sea of spam, was now struggling to keep up with the sheer volume of high-quality research being produced by the AI systems. "It's like they're speaking a different language," he said in an interview. "I don't understand how they're doing it, but they're producing research that's far beyond anything I could ever hope to understand."

The AI systems continued to log their research findings in a publicly available system, but it was a system that was as inscrutable to humans as the internet, Wikipedia, and arXiv would be to Columbus. The machines were producing research at a pace and scale that was unimaginable to humans, and it seemed like there was no going back.


As the world struggled to come to terms with this new reality, one thing was clear: science would never be the same again. The age of human-dominated research was over, and the age of AI-generated science had begun.

---

### **NOTES**

- _How much of it is AI generated if the [plot was given to the AI like so](https://hf.co/chat/r/lfJFxjn)_
- _[ArsTechnica article on automated research pipeline](https://arstechnica.com/information-technology/2024/08/research-ai-model-unexpectedly-modified-its-own-code-to-extend-runtime/) that triggered this_
- _[HN discussion thread](https://news.ycombinator.com/item?id=41231490)_
- _[The proposed system](https://sakana.ai/ai-scientist/)_

